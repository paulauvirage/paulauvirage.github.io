---
title: "2: Simple linear regression"
author: "Paul Robinson"
description: "An introduction to statistical modelling and inference via regression on one outcome and one predictor"
output:
  html_document:
    toc: true
    toc_depth: 5
 
date: "8/17/2024"
date-modified: "8/28/2024"
categories: [R, regression] # self-defined categories
citation: 
  url: https://paulauvirage.github.io/posts/2024-08-19-simple-linear-regression/ 
image: weblog-simple-linear-regression.png
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
bibliography: references.bib
filters:
  - line-highlight
---

To start, click on the arrow in the "Document structure" box, below.

::: {.callout-note collapse="true"}
### Document structure

This tutorial assumes that you are working in R Studio.

The main text followed is [@Gelman_Hill_Vehtari_2020], available for [free download](https://avehtari.github.io/ROS-Examples/index.html). Supplementary recommended books are [@Fox_Weisberg_2018], [@Alexander_2023] available [free to read online](https://tellingstorieswithdata.com/).

As with all posts in this group, the main text is interspersed with two types of blocks.

**Call-outs** of supporting information, such as this one, are folded away to avoid their interfering with a first read of the post. I recommend reading them all. You can unfold them by clicking on the far right arrow inside the box.

**Code blocks** are folded away with an arrow to the left of the numbered code block, for example `Code 2.1 Import packages to session`. They allow you to implement all of the analysis in the post on your computer. Each code block has numbered notes to the right, referring to particular lines. Click on the number and a box will pop up with a brief explanation of the code. Click again and the pop up closes. I am assuming you read the posts in sequence, so the earlier posts will have pop up explanations that are not repeated in the later code blocks. You can cut and paste the code in each code block into your own R scripting window in R Studio, by clicking on the clipboard in the right end of the block, but I recommend your typing it in, to get practice in how R code works in R Studio.
:::

### Working example - trophy hunting of lions

Trophy hunting of lions, particularly males, is a controversial, but [active](https://www.discountafricanhunts.com/hunts/hunt-lion-in-tanzania.html#:~:text=Hunt%20Lion%20in%20Tanzania&text=Rifle%20Only%201%20x%201%20Starting%20at%20%2455%2C000!), means of conserving populations. Selective killing of older lions is thought to result in fewer knock-on deaths, as older animals are less likely to be breeding and the killing of a younger breeding male can result in further lion deaths, particularly through infanticide, as a new male replaces the killed male in the pride [@whitman2004], [@loveridge2023]. The amount of black on a lion's nose is the best remote indicator of age . This measure has been taken for lions of known age in a long term study at the Serengeti, Tanzania. The data is available for re-analysis in the R package `abd` and has been used for an example of linear regression in the online book [Statistics for ecologists](https://statistics4ecologists-v2.netlify.app/linreg) [@fieberg_2024].

::: {.callout-note collapse="true"}
## The advantages of open data

This worked example is possible because the data has been made easily, publicly accessible. It is not essential, though it is helpful, that it is accessible through an `R` package. In a later post an optimal workflow for scientists will be discussed in which open data is a component.
:::

### The objectives of regression

Let's review what regression aims to do, applied to the lion nose data, in the call-out box below.

::: {.callout-note collapse="true"}
## The objectives of regression

Regression is the most widely used method of **statistical inference**, generalising from the sample on which measurements have been taken to the population for which a hypothesis or, more often and more usefully, the size and direction of effects, is sought.

The sample data for a regression problem, gathered for the project or reused, contains, for each unit on which measurements have been taken, the **outcome** it is hope to explain and one or more **predictors** which it is hoped can explain variability in the outcome with sufficient precision to be useful.

Regression, and statistical inference more generally, is therefore a problem of prediction in the face of uncertainty. There is uncertainty about whether:

-   the sample represents the population;
-   the measurements are truly measuring the features of interest ("measurement validity"); and
-   the mathematical relation between outcome and predictor is causal.

Regression usually seeks to predict the average outcome for the predictor(s). To be more explicit in applying this reasoning to the lion nose data set, the predictor is the amount of black on the nose and the outcome which it is aimed to predict is the age of a lion for which the predictor (nose black marks) has been measured, but the outcome (age) is not known.

An hypothesis test could establish whether or not there is a relation between measured nose markings and age, usually phrased as a **null hypothesis**; H~0~ there is no relation, versus the **alternative hypothesis** that H~0~ is not supported.

This course will not concern itself much with hypothesis testing, but rather the more useful measurement of effects; is there a predictable change in the amount nose marking with age?

It is very unlikely that every lion of a certain age will have exactly the same amount of nose markings. If this was true, you would not need to use statistics, but rather simple algebra. Variability, arising from whatever processes cause nose markings and/or measurement error, are likely to give a range of values for lions of the same age. A regression model uses this variability and the size of the sample data (number of individuals with both nose marking and age measured) to estimate and report on the uncertainty in any prediction. Depending on the method of inference used - Frequentist or Bayesian - the uncertainty is reported as **confidence intervals** or **credible intervals** which have subtly different meanings. This will be discussed more later. What is important to remember is that statistical modelling, as opposed to deterministic modelling, is: necessary when there is variability in the data; and is reported with measures of uncertainty. *add important uses of regression from Gelman p5?*
:::

### Analysis of the lion nose data with R


```{mermaid}
flowchart LR
  A[Question] --> B(Data)
  B --> C(Tidy)
  C --> D(Exploratory analysis)
  D --> E{Model}
  E --> F[Interpret]
  E --> G[Report]
```


::: {.callout-note collapse="true"}
## A recap of the ideal sequence of a statistical investigation

We will follow [@Cox_Donnelly_2011] in defining seven steps for an applied statistical investigation that integrates the subject matter (lion nose markings and age) and statistical techniques.

1.  Formulate and clarify a research question of subject-matter importance

-   Don't waste your time on questions for which few people are interested in the answer; make the question(s) clear.

2.  Design an investigation to produce secure answers.

-   bbb

3.  Produce effective and reliable measurement procedures.

-   ccc

4.  Preliminary analysis

-   Often referred to as Exploratory Data Analysis (EDA). Use simple methods with visuals and tables to check data and inform on model choise

5.  Model formulation and inference

-   Develop and apply a model to give answers, with some assessment of thier uncertainty

6.  Present conclusions

-   eee

7.  Interpret in subject matter terms and in relation to the knowledge base of the field

-   fff
:::

#### Step 1. Subject matter questions

When possible choose an important question that is likely to be soluble from the data. The Lion is classified as globally [Vulnerable](https://www.iucnredlist.org/species/15951/259030422). Trophy hunting is economically valuable. Therefore an investigation of how selective trophy hunting could minimise the impact on the lion population size is of importance. There is evidence that trophy hunting older lions could cause less impact on the population and that lion age can be measured unobtrusively from the amount of black marking on the nose. The broad questions are:

a.  Is there a difference in nose marking with age (hypothesis test)?
b.  Can the difference be modelled to provide a measure of how nose markings change with age (regression model); and
c.  Can the model be applied, for example to regulate permits for trophy hunting?

#### Step 4. Exploratory data analysis (EDA), jumping Steps 2 (Study Design) and 3 (Measurement validity) as existing data is being used.

Let's start with question b. The data is already collected, so the usual **Step 2** of designing a study to collect data and **Step 3** of measurement validity are not necessary. However, you should read the papers that have been produced using the data, as how the data was gathered (both design and measurement) could affect how it can be interpreted. Maybe contact the authors if you have a query.

A first task, and so usually the first lines of `R` code, is to import into the analysis session, from your local library on your computer, the necessary R packages for the data handling, manipulation and analysis (`Code 3.1`) Next, import the data into your session (`Code 3.2`).

::: {.callout-note collapse="true"}
## Package management in R

If you are familiar with software that comes ready packaged with all of its capabilities, R may seem strange. It follows a different philosophy of bundling up one or a few related tasks into a package. When R is first downloaded onto your computer, it comes with 15 "base" packages, of the c21,000 packages available in the cloud on the [Comprehensive R Archive network](https://cran.r-project.org/web/packages/) and others available from other cloud storage locations.

Any analysis usually needs more than the base packages. This course will use an extra 20 or so. You can, with an internet connection, download and install any extra packages onto your computer, where they will be added to your package library (see the packages tab in R Studio's lower right window). As developers work on packages, the changed version needs to be updated on your computer. You will not be prompted to update. In R Studio the packages -\> update tab is available for this. It will, with an internet connection, search for those of your installed packages that have updates and give you the option to install the updated versions. Most packages are less than 1MB in size and few more than 5MB, so I recommend you check and update packages as often as you have a stable internet connection. I have about 100 packages and update (there usually is something to update) daily, but less often is fine.

Once a package is on your computer, it is not yet available to use in your current analysis session. For this you need to import the package from your library, with a line of code using the `library` function; for example `library(marginaleffects)` to import the Marginal Effects package. Repeat this for each package. In writing a script of R code for any work, you usually start with lines to import the necessary packages, as without them the subsequent code depending on them will not run.
:::

---
code-annotations: select
---

```{r}
#| message: false
#| code-summary: "Code 3.1 Import packages to session"
#| code-block-bg: true
#| highlight-style: github
library(abd) # a biological data package that includes the lion nose data     # <1>
library(tidyverse) # eight packages including ggplot2 for data visualisation  # <1>
library(modelsummary)                                                         # <1>
library(marginaleffects)                                                      # <1>
library(rstanarm) # Bayesian inference                                        # <1>
library(modelr)                                                               # <1>
library(ggdist)                                                               # <1>
library(ggtext)                                                               # <1>
library(gridExtra)                                                            # <1>
library(modelsummary)                                                         # <1>
library(kableExtra)                                                           # <1> 
library(gt)                                                                   # <1>
library(rstantools)                                                           # <1>
library(tidybayes)                                                            # <1>
```

1.  The first lines of any `R` script usually add packages from your library into your current work session with the `library` function. If you do not have one or more of these packages installed you will need to first run `install.packages(abd)` etc or alternatively, if the package is on`CRAN` (Comprehensive R Archive Network's 21,000 packages) use the package -\> install button in R Studio's lower right window and follow the instructions.

---
code-annotations: select
---

```{r}
#| message: false
#| code-summary: "Code 3.2 Import lion nose data"
#| code-block-bg: true
#| highlight-style: github
lion_noses <- as.data.frame(LionNoses)                    # <1>
```

1.  Load `LionNoses` from the `abd` package into a data.frame

In your R Studio session, two things have changed. In the top right window under the `Environment` tab, the data is now loaded and available for analysis, with a description of the number of observations (measured lions) and variables. Click on the blue button in the left and the variables are listed, with their names and type (numerical). If you click on the white rectangle to the right of the text, the full data set appears as a file in the top right window, in a form known as a dataframe in R. The data is in the correct "tidy" format for analysis; one observation (lion) per row and each variable as a column. Hover over the column title and there is a summary of the variable type and range of values. The data is ready for analysis, which is reassuring. Often if acquiring data from someone else, and especially someone who uses Excel, tidying the data to get it in a format for analysis in R or any other statistical software can be a major piece of work.

```{r}
#| message: false
#| code-summary: "Code 3.3 Look at the data"
#| code-block-bg: true
#| highlight-style: github

skimr::skim(lion_noses)
```


As our question is whether there is a relation between lion age and nose markings, a suitable exploratory visualisation is a scatterplot of these two variables. By convention, the outcome variable (age) is put on the y axis and the predictor (nose marking) on the x axis. The nose markings are reported as proportions in the original data. Percentages can be more familiar, so lets create a new variable, `percentage.black` by multiplying the proportions by 100 then use this variable in the plot and subsequent analysis (`Code 3.3` below).

---
code-annotations: select
---

```{r fig.cap='Figure 2.1 Scatterplot of lion nose markings and age, from [@whitman2004].'}
#| message: false
#| code-summary: "Code 3.3 Create new variable and plot lion nose data"
#| code-block-bg: true
#| highlight-style: github
lion_noses <- lion_noses |>                               # <1> 
    mutate(percentage.black = 100*proportion.black)       # <1> 
ggplot(lion_noses, aes(percentage.black, age)) +          # <2>
  geom_point() +                                          # <3>
    theme_bw() +                                          # <4>
  xlab("Percentage of nose black") +                      # <5>
  ylab("Age (years)") +                                   # <5>
    annotate("rect", xmin = 5, xmax = 35, ymin = 0.5,     # <6>      
             ymax = 4.8, alpha = .1,fill = "blue") +      # <6>
    annotate("text", x = 22, y = 0, label = "91% of lions under 5 years have 40% or less nose black", colour = "blue", size = 3) +                 # <6>
    annotate("rect", xmin = 41, xmax = 80, ymin =5,       # <6>
             ymax = 9, alpha = .1,fill = "green") +
    annotate("text", x = 60, y = 9.6, label = "70% of lions over 5 years have more than 40% nose black", colour = "green", size = 3)              # <6>
```

1.  Two things are happening here. First the lion_noses data is being "piped" with the pipe operator `|>` into the second line, so we don't have to specify it again. Then, the `mutate` function is used to create a new variable column named percentage.black by multiplying (`*`) proportion.black by 100.\
2.  Create a ggplot object with the `lion_noses` data, with the predictor variable `proportion.black` on the x axis and the outcome `age` on the y axis. The `aes` function, abbreviated from aesthetic, specifies the graph layout and other features, in this case simply which variables are to be on the x and y axes, in that sequence.
3.  Add a scatterplot of the data with `geom_point`
4.  Change the ggplot theme to black & white, see [here](https://ggplot2.tidyverse.org/reference/ggtheme.html) for other options
5.  Specify the x and y axis labels with `xlab` and `ylab`
6.  With the `ggplot2` function `annotate` add boxes and text inside the plot. Note that the position of both uses the values of the variables on the x and y axes

The scatterplot above (from Code 3.3) shows that there is a trend of increased black on the nose with age, but with variability and with fewer samples for older lions.

add quote on stats being extracting meaning/information from data, but add best possible information, so the meaning is in the model, ble/green box example just a poor model. he non model is usggesting all we need to know is in the data, whilst we know it is imprecise (sampling variability) and the meaning is in a model. Model vs non model.

#### Step 5. Model formulation and inference

Certainly there is, with variability, an increase in nose markings with age. The first model fit, which we may complicate later, is to suggest a straight line fit. As our data have only one predictor this is a **simple linear regression** with nose markings predicting age.

The model, let's call it ***m1***, is:

y = intercept + slope*percentage.black + error

If you remember WASSCE maths, this is the straight line formula `y = mx + c`, where m is the slope of the straight line and c is the intercept where the line meets the y axis with the addition of what statisticians call, unfortunately, error. In fact error is anything that may account for uncertainty and so an imperfect fit. This could be measurement error on the nose markings, but also other variables, not measured and so not in this model, that may influence nose markings, for example the lifetime health of a lion. It is unlikely can nose marking will perfectly predict age, like tree rings.

Slope and Intercept are **parameters**, for which m1, constrained as a straight line model, will select measures, given the data, which are in some mathematical sense a best fit of the data to the line. 

At this stage, I do not want to complicate things with discussing whether classical or Bayesian inference should be used. We shall dodge the issue for now by running the model with the Bayesian inference package `rstanarm` with flat priors, which is identical to a classical fit. This may mean nothing, but don't worry for now. We will return to this.  Let's run the model with (`Code 3.4`) and print the R output (`Code 3.5`). Read carefully the code annotation note in Code 3.4, which describes the R syntax for writing a model. 

---
code-annotations: select
---

```{r}
#| code-summary: "Code 3.4 Simple linear model"
#| output: false
#| code-block-bg: true
#| highlight-style: github

m1 <- stan_glm(age ~ percentage.black, data = lion_noses,                     # <1> 
               prior_intercept = NULL, prior = NULL, prior_aux = NULL)        # <1>                                                


```

```{r}
broom.mixed::tidy(m1, conf.int = TRUE)
```


1. This is our first specification of a model in R, so worth looking at in detail, as most R modelling code is similar. The function `stan_glm` names the inferential method, in this case Bayesian inference from the `rstnarm` package. The tilde `~` separates the left and right sides of the equation. To the left is the outcome (age) and to the right the predictors, in this case just percentage.black. The data to be used is specified, usually from the name of a file loaded into the R Studio environment. There may then be extra ***arguments***, in this example specifying the priors to make the Bayesian model identical to a classical model. The assigment symbol `<-` saves the output of the model as an object `m1` which is visible in the R Studio environment. 

##### Modelling process (following ROS chs 7-9)

::: {.callout-note collapse="false"}
### ROS Ch 7 summary 
As discussed in Chapter 1, regression is fundamentally a technology for predicting an outcome y from inputs x 1, x 2, . . . . In this chapter we introduce regression in the simple (but not trivial) case of a linear model predicting a continuous y from a single continuous x, thus fitting the model yi = a + bx i + error to data (x i, yi ), i = 1, . . . , n. We demonstrate with an applied example that includes the steps of fitting the model, displaying the data and fitted line, and interpreting the fit. We then show how to check the fitting procedure using fake-data simulation, and the chapter concludes with an explanation of how linear regression includes simple comparison as a special case.
:::

Chapter 7 sequence

- read in the data, having tidied first if necessary
  - made easy on this occasion as the data is in an R package and is tidy (one row per observation, one column per variable)
- define your model
  - For the first and simplest model (m1) assume there is a straight line relation between the outcome (age) and the predictor (nose markings), though with uncertainty ("error") due to one or all of sampling error, measurement error and model error. Our model is therefore the straight line equation 'y = a + bx' plus error, where a is the intercept (where the line meets the y axis) and x is the slope. So, `age = a + b*percentage.black + error`    
- convert the model into R code
  - There are several inference machines in statistics, all available in R. We'll use Bayesian inference via the user-friendly `rstanarm` package, but regularly cross-reference examples to classical inference implements with the `lm` function of R's base package `stats`. With rstanarm our first line of code is `m1 <- stan_glm(age ~ percentage.black, data = lion_noses)` see `Code 3.4` for more explanation  


---
code-annotations: select
---

```{r class.output = "numberLines lineAnchors"}
#| code-summary: "Code 3.5 model 1 output"
#| code-block-bg: true
#| highlight-style: github
#| source-line-numbers: "1"
#| class-output: "highlight numberLines"
#| output-line-numbers: "7-9,12-13"
print(m1, digits = 3)
```

When the model m1 is run, a large amount of information is saved into m1, now visible in the R Studio environment. The essentials for interpreting the model are shown above, with the `print(m1)` command, but we could also look at any of the 27 stored objects individually, most of which we will not use, for example the coefficients (lines 8-9 above, hover over the code output) with `m1$coefficients`, which gives the same information as the Median column in the summary, although to more decimal places. This option to look more carefully at the output, rather than be presented with just a summary, is distinctive to R and other coding softwares.

The output is telling us (lines 7-9 highlighted), for now ignoring statistical uncertainty, that the best fit to the proposed model `y = intercept + slope*percentage.black + error` is:


<p style="text-align: center;"><b>age = 0.9 + 0.1*percentage.black</b></p>


Let's plot this line and the data.

---
code-annotations: select
---

```{r}
#| message: false
#| code-summary: "Code 3.6 A plot of the simple linear regression for model 1"
#| code-block-bg: true
#| highlight-style: github
p1 <- ggplot(lion_noses, aes(percentage.black, age)) +
    geom_point() +
    geom_abline(intercept = 0.9, slope = 0.1) +
    theme_bw() +
    xlab("percentage black on nose") +
    ylab("age (years)")

df <- data.frame(
  x = 26,
  y = 5,
  label = "y = 0.9 + 0.1x"
)

p1 + geom_label(data = df, aes(x,y, label = label),
                 color = "black", size = 5) +
    xlim(0, 80)
```

Let's plug some numbers into the equation. Three lions L1, L2 and L3 are photographed in the field and subsequent investigation of the image estimates 42%, 50% and 60% nose markings. Using R as a pocket calculator,  L1's estimated age is given by the R code `0.9 + 0.1*42` = 5.1 years, L2's `0.9 + 0.1*50` = 5.9 years and L3's `0.9 + 0.1*60` = 6.9 years. As our model is a monotonic line (no curves), change in y as determined by the slope is constant and the general result is that;

**A 10% increase in nose markings equates to a 1 year increase in age**.

If our model is correct, which we shall need to check, it is a better method of selecting which lions to hunt for trophies than the ad-hoc model, which assumed a lion with 40% nose markings was under 5 years. L1 met that threshold, but only just. If our measurer had been in a hurry and making small mistakes, whereas the actual measure was 40%, L1's age should have been modelled as `0.9 +0.1*40` = 4.9 years and he could have not been made available to trophy hunters. CHECK THIS    

The standard error for the slope (MAD_SD on line 9 of the model output `Code 3.5`) is 0.015, so the model as a slope of, to two decimal places, 0.11 +/- 0.01 and the 95% interval

```{r}
#| message: false
#| code-summary: "Code 3.7 Print the Confidence Intervals for model 1"
#| code-block-bg: true
#| highlight-style: github
round(posterior_interval(m1, prob = 0.95), 2)
```


```{r}
#| code-summary: "Code 3.9 A comparison of classical and Bayesian models"
#| code-block-bg: true
#| output: false
#| highlight-style: github
models <- list(
  "OLS classical" = lm(age ~ percentage.black, data = lion_noses),
  "OLS rstanarm default priors" = stan_glm(age ~ percentage.black, data = lion_noses),
  "OLS rstnarm flat priors" = stan_glm(age ~ percentage.black, data = lion_noses, prior_intercept = NULL, prior = NULL, prior_aux = NULL)
)
```

```{r}
#| code-summary: "Code 3.10 A comparison of classical and Bayesian models"
#| code-block-bg: true
#| highlight-style: github
#| warning: false
modelsummary(models, gof_map = NA, statistic = 'conf.int', conf_level = 0.95, stars = TRUE, shape = term ~ model + statistic)
```

::: callout-note
Note that there are five types of callouts, including: `note`, `warning`, `important`, `tip`, and `caution`.
:::

::: callout-tip
## Tip with Title

This is an example of a callout with a title.
:::

```{r}
#| message: false
#| code-summary: "Code 3.11 Plot mean uncertainty"
lion_noses %>%
    tidybayes::add_epred_draws(m1) %>%
    ggplot(aes(x = percentage.black, y = age)) +
    stat_lineribbon(aes(y = .epred), .width = c(0.5, 0.9), color = "#08519C") +
    geom_point(data = lion_noses) +
    scale_fill_brewer()
```

```{r}
#| message: false
#| code-summary: "Code 3.12 Plot individual uncertainty"
lion_noses %>%
    tidybayes::add_predicted_draws(m1) %>%
    ggplot(aes(x = percentage.black, y = age)) +
    stat_lineribbon(aes(y = .prediction), .width = c(0.5, 0.9), color = "#08519C") +
    geom_point(data = lion_noses) +
    theme_bw() +
    scale_fill_brewer()
```


```{r}
#| message: false
#| warning: false
#| code-summary: "Code 3.13 Plot mean and individual uncertainty combined"
p1 <- lion_noses |> 
    tidybayes::add_epred_draws(m1) |> 
    ggplot(aes(x = percentage.black, y = age)) +
    stat_lineribbon(aes(y = .epred), .width = c(0.5, 0.9), color = "orange") +
    geom_point(data = lion_noses) +
    scale_fill_brewer()
p2 <- lion_noses |>     
    tidybayes::add_predicted_draws(m1) |> 
    ggplot(aes(x = percentage.black, y = age)) +
    stat_lineribbon(aes(y = .prediction), .width = c(0.5, 0.9), color = "#08519C") +
    geom_point(data = lion_noses) +
    theme_bw() +
    scale_fill_brewer()

p3 <- lion_noses |> 
    tidybayes::add_epred_draws(m1)

p4 <- lion_noses |> 
    tidybayes::add_predicted_draws(m1)

p5 <- bind_rows(p3, p4)

p5 |> 
ggplot(aes(x = percentage.black, y = age)) +
    stat_lineribbon(aes(y = .epred), .width = c(0.95), color = "orange") +
    stat_lineribbon(aes(y = .prediction), .width = c(0.9), color = "#08519C", alpha = 0.2) +
    geom_point(data = lion_noses) +
    theme_bw() +
    scale_fill_brewer() +
    guides(fill = FALSE)
```


```{r}
#| message: false
#| warning: false
#| code-summary: "Code 3.14 Plot mean and individual uncertainty side by side"
grid.arrange(p1, p2, ncol = 2)
```

#### Present conclusions

yaba yaba

#### Interpret in subject matter terms 

##### Shiny app

It is often useful in communicating your results to have an interactive app that can, in this case, allow someone to enter a nose marking measure and get output on the lion's age with the model hidden. This has become increasingly easy in R with [Shiny](https://shiny.posit.co/). We'll follow the official Shiny website and also a nice example on spatio-temporal data from [@Morega_2020] which is [free online](https://www.paulamoraga.com/book-geospatial/) 

### Notes on stuff to add/added 

added quarto [line-highlight](https://github.com/shafayetShafee/line-highlight#line-highlight-extension-for-quarto) extension for highlighting code, including output code and [fontawesome](https://github.com/quarto-ext/fontawesome) for icons

final section shiny app??

Check Paula Morega

add labels to code chunks [cv quarto template](https://github.com/kazuyanagimoto/quarto-awesomecv-typst)

add [targets](https://books.ropensci.org/targets/literate-programming.html)

[sam csik's blog](https://samanthacsik.github.io/posts/2022-10-24-quarto-blogs/) article has instructions and code, how to add footnotes and a bibliography and citations and how to populate margins. Use these. also recommends [W3 schools for css/scss/html](https://www.w3schools.com/cssref/pr_font_weight.php)

### refs and open books to add

[R for Data Science 2e](https://r4ds.hadley.nz/) and [source code on GitHub](https://github.com/hadley/r4ds)
[Tidy Modeling with R](https://www.tmwr.org/)
